import os
import torch
import numpy as np
import psycopg2
from PIL import Image
from pgvector.psycopg2 import register_vector
import cv2
import SAM3_Adaptation

# ê¸°ì¡´ ì‘ì„±í•˜ì‹  í™˜ê²½ ì„¤ì • ë° ëª¨ë¸ ë¡œë“œ í™œìš©
from project_env import initialize_project
from sam3 import build_sam3_image_model

# 1. í™˜ê²½ ì´ˆê¸°í™” ë° ëª¨ë¸ ë¡œë“œ
initialize_project()
device = "cuda" if torch.cuda.is_available() else "cpu"

# SAM3 ë¡œë“œ (í•™ìŠµëœ ê°€ì¤‘ì¹˜ ì ìš©)
sam3_checkpoint = r"C:\Users\hjchung\Desktop\sam3\checkpoints\sam3.pt"
model_sam3 = build_sam3_image_model(checkpoint_path=sam3_checkpoint).to(device)

# í•™ìŠµì‹œí‚¨ ê°€ì¤‘ì¹˜ ë¡œë“œ
adapted_path= "sam3_good_adapted.pt"
if os.path.exists(adapted_path):
    # weights_only= TrueëŠ” ë³´ì•ˆì„ ìœ„í•´ ê¶Œì¥
    model_sam3.load_state_dict(torch.load(adapted_path, map_location=device, weights_only=True))
    print(f"âœ… í•™ìŠµëœ ê°€ì¤‘ì¹˜ ë¡œë“œ ì™„ë£Œ: {adapted_path}")

else:
    print(f"âš ï¸ ê°€ì¤‘ì¹˜ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ë² ì´ìŠ¤ ëª¨ë¸ë¡œ ì§„í–‰í•©ë‹ˆë‹¤: {adapted_path}")

model_sam3.eval()

# DINOv2 ë¡œë“œ
model_dinov2 = torch.hub.load('facebookresearch/dinov2', 'dinov2_vitb14').to(device)
model_dinov2.eval()


class SimpleBatch:
    def __init__(self, data):
        self.img_batch = data

    def __len__(self):
        return len(self.img_batch)

def get_bbox_from_mask(mask_tensor, threshold=0.5):
    """SAM3 ì¶œë ¥ ë§ˆìŠ¤í¬ì—ì„œ ê²°í•¨ ë¶€ìœ„ì˜ Bounding Box ì¢Œí‘œ ì¶”ì¶œ"""
    mask = (mask_tensor > threshold).cpu().numpy().astype(np.uint8)[0, 0]  # [H, W]
    coords = cv2.findNonZero(mask)
    if coords is not None:
        x, y, w, h = cv2.boundingRect(coords)
        return (x, y, w, h)
    return None

def extract_dinov2_feature(img_patch):
    """ì˜ë¼ë‚¸ ê²°í•¨ ì˜ì—­ì—ì„œ DINOv2 ë²¡í„° ì¶”ì¶œ"""
    from torchvision import transforms
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    img_t = transform(img_patch).unsqueeze(0).to(device)
    with torch.no_grad():
        features = model_dinov2(img_t)
    return features.cpu().numpy().flatten()

def process_and_save_to_db(folder_path, defect_label):
    # DB ì—°ê²°
    conn = psycopg2.connect(host="localhost", dbname="DefectRAGUpdate", user="postgres", password="3510")
    register_vector(conn)
    cur = conn.cursor()

    image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg'))]
    saved_count= 0     # ì €ì¥ëœ ê°œìˆ˜ ì„¸ê¸° ìœ„í•œ ë³€ìˆ˜

    print(f"\n--- [{defect_label}] ë°ì´í„° êµ¬ì¶• ì‹œì‘ ---")

    for img_name in image_files:
        full_path = os.path.join(folder_path, img_name)
        raw_image = Image.open(full_path).convert("RGB")

        # SAM3ìš© ì…ë ¥ ì „ì²˜ë¦¬
        input_img_res = raw_image.resize((1008, 1008))

        # tensor ë³€í™˜ ë° ì •ê·œí™”
        img_np= np.array(input_img_res) / 255.0     # 0~1 ë²”ìœ„ë¡œ ì •ê·œí™”
        input_tensor = torch.as_tensor(np.array(input_img_res)).permute(2, 0, 1).float().unsqueeze(0).to(device)

        with torch.no_grad():
            # try:
                # SAM3ë¥¼ í†µí•´ ë§ˆìŠ¤í¬ ìƒì„±
                output = model_sam3(SimpleBatch(input_tensor))

                # ë§ˆìŠ¤í¬ í…ì„œ ì¶”ì¶œ (ëª¨ë¸ êµ¬ì¡°ì— ë”°ë¼ 'masks' ë˜ëŠ” 'low_res_masks' í™•ì¸ í•„ìš”)
                # mask_tensor = output.get('masks') or output.get('low_res_masks')

                # if mask_tensor is not None:
                #    bbox_info = get_bbox_from_mask(mask_tensor)

                 #   if bbox_info:
                  #      x, y, w, h = bbox_info
                        # ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°ì— ë§ê²Œ ì¢Œí‘œ ì—­ì‚° í•„ìš” ì‹œ ìˆ˜í–‰ (ì—¬ê¸°ì„œëŠ” 1024 ê¸°ì¤€ crop)
                   #     cropped_patch = input_img_res.crop((x, y, x + w, y + h))

                        # DINOv2 íŠ¹ì§• ì¶”ì¶œ
                    #    feature_vec = extract_dinov2_feature(cropped_patch)

                        # DB ì €ì¥
                     #   cur.execute("""
                      #      INSERT INTO defect_features
                       #     (defect_type, feature_vector, bbox_x, bbox_y, bbox_w, bbox_h, image_path)
                        #    VALUES (%s, %s, %s, %s, %s, %s, %s)
                        #""", (defect_label, feature_vec, x, y, w, h, full_path))
                        #saved_count += 1
                        #print(f"âœ… {img_name} ì €ì¥ ì™„ë£Œ")

                    #else:
                     #   print(f"âš ï¸ {img_name}: ê²°í•¨ ë§ˆìŠ¤í¬ê°€ íƒì§€ë˜ì§€ ì•ŠìŒ")

                #else:
                 #   print(f"âš ï¸ {img_name}: ëª¨ë¸ ì¶œë ¥ì—ì„œ ë§ˆìŠ¤í¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")

            #except AssertionError as e:
             #   print(f"âŒ {img_name}: ëª¨ë¸ ì…ë ¥ ê·œê²© ë¶ˆì¼ì¹˜ (1024 í•´ìƒë„ í™•ì¸ í•„ìš”)")
              #  continue

    conn.commit()
    cur.close()
    conn.close()

    print(f"âœ… ì•Œë¦¼: [{defect_label}] í´ë” ì²˜ë¦¬ ì™„ë£Œ!")
    print(f"ğŸ“Š ìš”ì•½: ì´ {len(image_files)}ê°œ ì¤‘ {saved_count}ê°œì˜ ë°ì´í„°ê°€ DBì— ì •ìƒ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print(f"--------------------------------------\n")

if __name__ == "__main__":
    # ê° defectë³„ í´ë” ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
    defects = [
        ("crack", r"C:\Users\hjchung\Desktop\RAG Train\crack"),
        ("fabDefect", r"C:\Users\hjchung\Desktop\RAG Train\fabDefect"),
        ("ink", r"C:\Users\hjchung\Desktop\RAG Train\ink"),
        ("mapout", r"C:\Users\hjchung\Desktop\RAG Train\mapout"),
        ("particle", r"C:\Users\hjchung\Desktop\RAG Train\particle"),
        ("unknown", r"C:\Users\hjchung\Desktop\RAG Train\unknown")
    ]

    for label, path in defects:
        try:
            process_and_save_to_db(path, label)
        except Exception as e:
            print(f"âŒ ì—ëŸ¬ ë°œìƒ [{label}]: {e}")

            import traceback
            traceback.print_exc()
            # ì—ëŸ¬ê°€ ë°œìƒí•´ë„ ë‹¤ìŒ í´ë”ë¡œ ë„˜ì–´ê°€ë„ë¡ ì²˜ë¦¬
            continue

    print("ğŸ‰ ëª¨ë“  ê²°í•¨ ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶• ê³µì •ì´ ìµœì¢… ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")