import sys
import torch
from types import ModuleType
from unittest.mock import MagicMock
import importlib.util

# Triton Mock ì„¤ì •
def mock_triton():
    if 'triton' not in sys.modules:
        m= ModuleType('triton')
        m.__spec__= importlib.util.spec_from_loader('triton', loader= None)
        m.jit= lambda f= None, **k: (f if f else lambda x: x)
        m.autotune= m.jit
        m.Config= MagicMock()
        sys.modules['triton'] = m

        for s in ['language', 'runtime', 'compiler']:
            s_name= f"{'triton'}.{s}"
            sm= ModuleType(s_name)
            sm.__spec__= importlib.util.spec_from_loader(s_name, loader= None)

            if s== 'language':
                sm.constexpr= lambda x: x
                sm.float32, sm.int32, sm.int64= torch.float32, torch.int32, torch.int64
                sm.arange, sm.exp= torch.arange, torch.exp
                sm.load, sm.store, sm.dot= MagicMock(), MagicMock(), MagicMock()
                sm.max_contiguous= lambda x, y: x
            sys.modules[f'triton.{s}'] = sm

mock_triton()

import os
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader
from PIL import Image
import numpy as np
from torchvision import transforms
from sam3 import build_sam3_image_model
from project_env import initialize_project
from config import bpe_path
from config import sam3_checkpoint
import sam3.model.vitdet as vitdet

target_size= 2224

def preprocess_image(img_tensor, targetSize= (target_size, target_size)):
    """
    ì–´ë–¤ í¬ê¸°ì˜ ì´ë¯¸ì§€ê°€ ë“¤ì–´ì˜¤ë“  ëª¨ë¸ì´ ì›í•˜ëŠ” target_sizeë¡œ ê°•ì œ ê³ ì •
    img_tensor: [B, C, H, W] í˜•íƒœ
    """
    # í˜„ì¬ í¬ê¸° í™•ì¸
    curr_h, curr_w = img_tensor.shape[-2:]

    # ì´ë¯¸ íƒ€ê²Ÿ ì‚¬ì´ì¦ˆë¼ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
    if(curr_h, curr_w) == targetSize:
        return img_tensor
    print(f" [ì „ì²˜ë¦¬] ì´ë¯¸ì§€ í¬ê¸° ë³€ê²½: ({curr_h}, {curr_w}) -> {targetSize}")

    # ëª¨ë¸ì´ í—ˆìš©í•˜ëŠ” í¬ê¸°ë¡œ ê°•ì œ ë¦¬ì‚¬ì´ì§•
    # SAM3ëŠ” ì •ì‚¬ê° ì…ë ¥ ì„ í˜¸ -> align_cornersëŠ” Falseê°€ ì¼ë°˜ì 
    return F.interpolate(img_tensor, size= targetSize, mode="bilinear", align_corners=False)

def patched_reshaped_for_broadcast(freqs_cis, x):
    """
    ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ AssertionError ìš°íšŒí•˜ê¸° ìœ„í•œ íŒ¨ì¹˜
    """
    # ì‹¤ì œ ì—°ì‚°ì— í•„ìš”í•œ í˜•íƒœë¡œ ë³€í™˜ (1, L, 1, D)
    ndim= x.ndim
    assert ndim>= 2
    # ndim-2 (ì‹œí€€ìŠ¤ ê¸¸ì´)ì™€ ndim-1 (í—¤ë“œ ì°¨ì›)ì„ ìœ ì§€
    shape= [d if i in (ndim- 2, ndim- 1) else 1 for i, d in enumerate(x.shape)]
    return freqs_cis.view(*shape)

# ë¼ì´ë¸ŒëŸ¬ë¦¬ í•¨ìˆ˜ë¥¼ ìš°ë¦¬ê°€ ë§Œë“  íŒ¨ì¹˜ í•¨ìˆ˜ë¡œ êµì²´
vitdet.reshape_for_broadcast= patched_reshaped_for_broadcast

class DummyInput:
    """ëª¨ë¸ ë‚´ë¶€ì—ì„œ ìš”êµ¬í•˜ëŠ” ì†ì„±ë“¤ì„ ê°–ì¶˜ ê°€ì§œ ì…ë ¥ ê°ì²´"""

    def __init__(self, tensor):
        self.image = tensor
        self.input_points = None
        self.input_labels = None
        self.input_boxes = None

    def __getattr__(self, name):
        """
        ì •ì˜ë˜ì§€ ì•Šì€ ì†ì„± (input_boxes_label ë“±)ì„ í˜¸ì¶œí•  ë•Œ AttributeError ë‚´ëŠ” ëŒ€ì‹  None ë°˜í™˜
        """
        return None

class SimpleBatch:
    def __init__(self, tensor):
        # ëª¨ë¸ì´ ì§ì ‘ ì°¸ì¡°í•˜ëŠ” img_batch ì„¤ì •
        self.img_batch= tensor
        self.dummy_item= DummyInput(tensor)

    @property
    def find_inputs(self):
        return [self.dummy_item]

    @property
    def find_text_batch(self):
        return [""]

    @property
    def find_targets(self):
        return [self.dummy_item]

    def __iter__(self):
        return iter([self.dummy_item])
    def __len__(self):
        return 1
    def __getitem__(self, index):
        return self.dummy_item

    def to(self, device):
        self.img_batch = self.img_batch.to(device)
        self.dummy_item.image= self.img_batch
        return self

# ë°ì´í„°ì…‹ ìˆ˜ì • (í‘œì¤€ ì „ì²˜ë¦¬ ì ìš©)
class GoodImageDataset(torch.utils.data.Dataset):
    def __init__(self, base_path):
        self.path = os.path.join(base_path, 'good')
        self.images= [os.path.join(self.path, f) for f in os.listdir(self.path)
                      if f.lower().endswith(('.png', '.jpg'))]
        self.transform = transforms.Compose([
            transforms.Resize((target_size, target_size)),
            transforms.ToTensor(),
            # transforms.Normalize(mean= [0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        img= Image.open(self.images[idx]).convert("RGB")
        # ê°•ì œë¡œ í¬ê¸° ê³ ì •
        img= img.resize((target_size, target_size), Image.BILINEAR)
        return self.transform(img)

# 3. í•™ìŠµ ë£¨í”„ (ë¡œì»¬ GPU ë©”ëª¨ë¦¬ ê³ ë ¤)
def run_adaptation():
    initialize_project()
    device= "cuda" if torch.cuda.is_available() else "cpu"

    print("ğŸ”„ ëª¨ë¸ ë¡œë“œ ì¤‘...")

    model= None     # ì´ˆê¸°ê°’ ì„¤ì •
    try:
        # ì¼ë°˜ì ì¸ SAM2/3 ë¹Œë” í˜•ì‹ (ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œë§Œ ì „ë‹¬)
        model= build_sam3_image_model(
            bpe_path= bpe_path,
            checkpoint_path= sam3_checkpoint
        ).to(device)
        print("âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ")

    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return     # ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ ì‹œ í•¨ìˆ˜ ì¢…ë£Œ (ì´í›„ ì½”ë“œ ì‹¤í–‰ ë°©ì§€)

    model.train()

    dataset = GoodImageDataset(r"C:\Users\hjchung\Desktop\RAG Train")
    loader = DataLoader(dataset, batch_size=1, shuffle=True)  # ë¡œì»¬ OOM ë°©ì§€
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-6)

    print(f"ğŸš€ ë¡œì»¬ GPU({device})ì—ì„œ SAM3 ì •ìƒ íŒ¨í„´ í•™ìŠµ ì‹œì‘...")

    for epoch in range(3):  # ê³¼ì í•© ë°©ì§€ë¥¼ ìœ„í•´ ì ê²Œ ìˆ˜í–‰
        for i, batch in enumerate(loader):
            optimizer.zero_grad()
            # ë°ì´í„°ë¥¼ ëª¨ë¸ê³¼ ë™ì¼í•œ ì¥ì¹˜ë¡œ ì´ë™
            input_data= SimpleBatch(batch).to(device)
            # ì´ë¯¸ì§€ í¬ê¸° ê³ ì • ì „ì²˜ë¦¬ ê³¼ì •
            input_data.img_batch= preprocess_image(input_data.img_batch, targetSize= (target_size, target_size))
            # ë©”ëª¨ë¦¬ í¬ë§·ê³¼ ë°ì´í„° íƒ€ì…ì„ ëª¨ë¸ì˜ backboneì— ë§ì¶¤
            input_data.img_batch= input_data.img_batch.to(memory_format=torch.contiguous_format)

            # print(f"DEBUG: img_batch shape: {input_data.img_batch.shape}")

            target_res= 2528

            if input_data.img_batch.shape[-1:]!= target_size:
                print(f" [ì „ì²˜ë¦¬] ëª¨ë¸ ìš”êµ¬ ì‚¬ì–‘ì— ë§ì¶° {input_data.img_batch.shape[-2:]} -> ({target_res}, {target_res})ë¡œ ê°•ì œ ê³ ì •í•©ë‹ˆë‹¤.")

                input_data.img_batch= F.interpolate(
                    input_data.img_batch,
                    size= (target_res, target_res),
                    mode="bilinear",
                    align_corners=False
                )

            try:
                # ìë™ í˜¼í•© ì •ë°€ë„(Autocast) ì‚¬ìš© (SAM3 ë‚´ë¶€ RoPE ì—°ì‚° ì˜¤ë¥˜ ë°©ì§€)
                with torch.amp.autocast('cuda', dtype= torch.bfloat16):
                    # ëª¨ë¸ ì¶”ë¡ 
                    output = model(input_data)

                target_feat= None
                if isinstance(output, dict):
                    for key in ['high_res_feats', 'vision_features', 'image_embed']:
                        if key in output.get(key) is not None:
                            target_feat = output[key]
                            break

                if target_feat is not None:
                    # íŠ¹ì§•ê°’ ë³µì› í•™ìŠµ (ì •ìƒ íŒ¨í„´ ì•”ê¸°)
                    loss = nn.MSELoss()(target_feat, target_feat.detach().clone())
                    loss.backward()
                    optimizer.step()

                    if i% 10==0:
                        print(f"Epoch {epoch+1} [{i}/{len(loader)}] Loss: {loss.item():.6f}")

                    else:
                        print("âš ï¸ ìœ íš¨í•œ íŠ¹ì§•ëŸ‰ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

            except AssertionError:
                print(f"âŒ RoPE í•´ìƒë„ ë¶ˆì¼ì¹˜ ë°œìƒ!")
                import traceback
                traceback.print_exc()

                found= False
                # ëª¨ë¸ì˜ ëª¨ë“  í•˜ìœ„ ëª¨ë“ˆ ë’¤ì ¸ì„œ RoPE ì„¤ì •ê°’ ì°¾ê¸°
                for name, module in model.named_modules():
                    if hasattr(module, 'freqs_cis'):
                        freqs= module.freqs_cis

                        if freqs is not None:
                            print(f" - [ë°œê²¬] ëª¨ë“ˆ ìœ„ì¹˜: {name}")
                            print(f" - [ë°œê²¬] RoPE í˜•ìƒ: {freqs.shape}")

                            import math
                            # SAM ê³„ì—´ì€ ë³´í†µ (H*W/256, D) í˜•íƒœë¥¼ ê°€ì§‘ë‹ˆë‹¤.
                            # ë§Œì•½ shape[0] ì´ 4096ì´ë©´ 64x64 ê·¸ë¦¬ë“œ -> 1024x1024 í•´ìƒë„
                            num_patches= freqs.shape[0]
                            side= int(math.sqrt(num_patches))
                            print(f" - ì¶”ì • ê·¸ë¦¬ë“œ í¬ê¸°: {side} x {side}")
                            print(f" - ê¶Œì¥ ì…ë ¥ í•´ìƒë„: {side * 16} x {side * 16}")
                            found= True
                            break     # í•˜ë‚˜ë§Œ ì°¾ìœ¼ë©´ ì¤‘ë‹¨

                if not found:
                    print(" - ëª¨ë¸ ë‚´ë¶€ì—ì„œ freqs_cis ì†ì„±ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

                print(f" - í˜„ì¬ ì…ë ¥ í…ì„œ í¬ê¸°: {input_data.img_batch.shape}")
                break

            except Exception as e:
                print(f"âŒ ê¸°íƒ€ ì—ëŸ¬ ë°œìƒ: {e}")
                import traceback
                traceback.print_exc()
                break

    torch.save(model.state_dict(), "sam3_good_adapted.pt")
    print("âœ… ë¡œì»¬ í•™ìŠµ ì™„ë£Œ! sam3_good_adapted.pt ì €ì¥ë¨.")

if __name__ == "__main__":
    run_adaptation()