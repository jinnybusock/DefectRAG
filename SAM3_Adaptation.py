import sys
import torch
from types import ModuleType
from unittest.mock import MagicMock
import importlib.util

# Triton Mock ì„¤ì •
def mock_triton():
    if 'triton' not in sys.modules:
        m= ModuleType('triton')
        m.__spec__= importlib.util.spec_from_loader('triton', loader= None)
        m.jit= lambda f= None, **k: (f if f else lambda x: x)
        m.autotune= m.jit
        m.Config= MagicMock()
        sys.modules['triton'] = m

        for s in ['language', 'runtime', 'compiler']:
            s_name= f"{'triton'}.{s}"
            sm= ModuleType(s_name)
            sm.__spec__= importlib.util.spec_from_loader(s_name, loader= None)

            if s== 'language':
                sm.constexpr= lambda x: x
                sm.float32, sm.int32, sm.int64= torch.float32, torch.int32, torch.int64
                sm.arange, sm.exp= torch.arange, torch.exp
                sm.load, sm.store, sm.dot= MagicMock(), MagicMock(), MagicMock()
                sm.max_contiguous= lambda x, y: x
            sys.modules[f'triton.{s}'] = sm

mock_triton()

import os
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader
from PIL import Image
import numpy as np
from torchvision import transforms
from sam3 import build_sam3_image_model
from project_env import initialize_project
from config import sam3_checkpoint

class DummyInput:
    """ëª¨ë¸ ë‚´ë¶€ì—ì„œ ìš”êµ¬í•˜ëŠ” ì†ì„±ë“¤ì„ ê°–ì¶˜ ê°€ì§œ ì…ë ¥ ê°ì²´"""

    def __init__(self, tensor):
        self.image = tensor
        self.input_points = None
        self.input_labels = None
        self.input_boxes = None

    def __getattr__(self, name):
        """
        ì •ì˜ë˜ì§€ ì•Šì€ ì†ì„± (input_boxes_label ë“±)ì„ í˜¸ì¶œí•  ë•Œ AttributeError ë‚´ëŠ” ëŒ€ì‹  None ë°˜í™˜
        """
        return None

class SimpleBatch:
    def __init__(self, tensor):
        # ëª¨ë¸ì´ ì§ì ‘ ì°¸ì¡°í•˜ëŠ” img_batch ì„¤ì •
        self.img_batch= tensor
        self.dummy_item= DummyInput(tensor)

    @property
    def find_inputs(self):
        return [self.dummy_item]

    @property
    def find_text_batch(self):
        return [""]

    @property
    def find_targets(self):
        return [self.dummy_item]

    def __iter__(self):
        return iter([self.dummy_item])
    def __len__(self):
        return 1
    def __getitem__(self, index):
        return self.dummy_item

    def to(self, device):
        self.img_batch = self.img_batch.to(device)
        self.dummy_item.image= self.img_batch
        return self

# ë°ì´í„°ì…‹ ìˆ˜ì • (í‘œì¤€ ì „ì²˜ë¦¬ ì ìš©)
class GoodImageDataset(torch.utils.data.Dataset):
    def __init__(self, base_path):
        self.path = os.path.join(base_path, 'good')
        self.images= [os.path.join(self.path, f) for f in os.listdir(self.path)
                      if f.lower().endswith(('.png', '.jpg'))]
        self.transform = transforms.Compose([
            transforms.Resize((512, 512)),
            transforms.ToTensor(),
            transforms.Normalize(mean= [0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        img= Image.open(self.images[idx]).convert("RGB")
        return self.transform(img)

# 3. í•™ìŠµ ë£¨í”„ (ë¡œì»¬ GPU ë©”ëª¨ë¦¬ ê³ ë ¤)
def run_adaptation():
    initialize_project()
    device= "cuda" if torch.cuda.is_available() else "cpu"
    sam3_checkpoint= r"C:\Users\hjchung\Desktop\sam3\checkpoints\sam3.pt"

    print("ğŸ”„ ëª¨ë¸ ë¡œë“œ ì¤‘...")
    model= build_sam3_image_model(checkpoint_path=r"C:\Users\hjchung\Desktop\sam3\checkpoints\sam3.pt").to(device)
    model.train()

    dataset = GoodImageDataset(r"C:\Users\hjchung\Desktop\RAG Train")
    loader = DataLoader(dataset, batch_size=1, shuffle=True)  # ë¡œì»¬ OOM ë°©ì§€
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-6)

    print(f"ğŸš€ ë¡œì»¬ GPU({device})ì—ì„œ SAM3 ì •ìƒ íŒ¨í„´ í•™ìŠµ ì‹œì‘...")

    for epoch in range(3):  # ê³¼ì í•© ë°©ì§€ë¥¼ ìœ„í•´ ì ê²Œ ìˆ˜í–‰
        for i, batch in enumerate(loader):
            optimizer.zero_grad()
            input_data= SimpleBatch(batch).to(device)

            try:
                # ëª¨ë¸ ì¶”ë¡ 
                output = model(input_data)

                target_feat= None
                if isinstance(output, dict):
                    for key in ['high_res_feats', 'vision_features', 'image_embed']:
                        if key in output[key] is not None:
                            target_feat = output[key]
                            break

                if target_feat is not None:
                    # íŠ¹ì§•ê°’ ë³µì› í•™ìŠµ (ì •ìƒ íŒ¨í„´ ì•”ê¸°)
                    loss = nn.MSELoss()(target_feat, target_feat.detach().clone())
                    loss.backward()
                    optimizer.step()

                    if i% 10==0:
                        print(f"Epoch {epoch+1} [{i}/{len(loader)}] Loss: {loss.item():.6f}")

                    else:
                        print("âš ï¸ ìœ íš¨í•œ íŠ¹ì§•ëŸ‰ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

            except AssertionError as e:
                expected_shape= "ì•Œ ìˆ˜ ì—†ìŒ"
                try:
                    expected_shape= model.backbone.trunk.blocks[0].attn.freqs_cis.shape
                except:
                    pass

                print(f"âŒ RoPE í•´ìƒë„ ë¶ˆì¼ì¹˜!")
                print(f" - í˜„ì¬ ì…ë ¥ í¬ê¸°: {input_data.img_batch.shape}")
                print(f" - ëª¨ë¸ ê¸°ëŒ€ RoPE í˜•ìƒ (H, W): {expected_shape}")
                break

            except Exception as e:
                print(f"âŒ ê¸°íƒ€ ì—ëŸ¬ ë°œìƒ: {e}")
                import traceback
                traceback.print_exc()
                break

    torch.save(model.state_dict(), "sam3_good_adapted.pt")
    print("âœ… ë¡œì»¬ í•™ìŠµ ì™„ë£Œ! sam3_good_adapted.pt ì €ì¥ë¨.")

if __name__ == "__main__":
    run_adaptation()